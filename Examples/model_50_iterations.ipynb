{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur_dir /home/sergey/mnt/st1500/Usr/Sergey/TheJob/Otus/ML_advanced2020/final_project\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.express as px\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import config\n",
    "import preprocess\n",
    "\n",
    "from custom_metrics import LoglossObjective_loop, LoglossObjective_np\n",
    "from custom_metrics import FocalLossFormulas, AsymmetricLossFormulas\n",
    "from custom_metrics import AsymmetricLossObjective\n",
    "from custom_metrics import get_simplified_derivative\n",
    "\n",
    "from collections import defaultdict\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "sys.path.append('./cython_loss')\n",
    "\n",
    "os.environ['PYARROW_IGNORE_TIMEZONE'] = '1'\n",
    "# import featuretools as ft\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "pd.set_option('display.max_rows', 120)\n",
    "plt.style.use(\"dark_background\")\n",
    "plt.rcParams['figure.figsize'] = (12, 5)\n",
    "plt.rcParams[\"hist.bins\"] = 50\n",
    "print('cur_dir', Path.cwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (274702, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": "   DealDurationDays  DealDurationMonths  Client_Id   DealDate  ValueDate  \\\n0               8.0                   0      16140 2015-01-12 2015-01-12   \n1              53.0                   1      21990 2015-01-12 2015-01-12   \n2              92.0                   3      18607 2015-01-12 2015-01-12   \n3               1.0                   0      20500 2015-01-12 2015-01-12   \n4               1.0                   0       4041 2015-01-12 2015-01-12   \n\n  MaturityDate  Deal_characteristics_1  Deal_characteristics_2  \\\n0   2015-01-20                7.018746                  0.0000   \n1   2015-03-06                0.306237                  0.1146   \n2   2015-04-14                0.306237                  0.1201   \n3   2015-01-13                2.985808                  0.0896   \n4   2015-01-13                0.418013                  0.0805   \n\n   Deal_characteristics_3  Deal_characteristics_4  Client_characteristics_1  \\\n0                0.140368                       0                        15   \n1                0.087720                       2                        15   \n2                0.054139                       2                        15   \n3                0.100056                       2                        15   \n4                0.168161                       2                        15   \n\n   Client_characteristics_2  target  \n0                      1759       1  \n1                      1759       1  \n2                      1759       1  \n3                      1759       1  \n4                      1759       1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DealDurationDays</th>\n      <th>DealDurationMonths</th>\n      <th>Client_Id</th>\n      <th>DealDate</th>\n      <th>ValueDate</th>\n      <th>MaturityDate</th>\n      <th>Deal_characteristics_1</th>\n      <th>Deal_characteristics_2</th>\n      <th>Deal_characteristics_3</th>\n      <th>Deal_characteristics_4</th>\n      <th>Client_characteristics_1</th>\n      <th>Client_characteristics_2</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8.0</td>\n      <td>0</td>\n      <td>16140</td>\n      <td>2015-01-12</td>\n      <td>2015-01-12</td>\n      <td>2015-01-20</td>\n      <td>7.018746</td>\n      <td>0.0000</td>\n      <td>0.140368</td>\n      <td>0</td>\n      <td>15</td>\n      <td>1759</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>53.0</td>\n      <td>1</td>\n      <td>21990</td>\n      <td>2015-01-12</td>\n      <td>2015-01-12</td>\n      <td>2015-03-06</td>\n      <td>0.306237</td>\n      <td>0.1146</td>\n      <td>0.087720</td>\n      <td>2</td>\n      <td>15</td>\n      <td>1759</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>92.0</td>\n      <td>3</td>\n      <td>18607</td>\n      <td>2015-01-12</td>\n      <td>2015-01-12</td>\n      <td>2015-04-14</td>\n      <td>0.306237</td>\n      <td>0.1201</td>\n      <td>0.054139</td>\n      <td>2</td>\n      <td>15</td>\n      <td>1759</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>0</td>\n      <td>20500</td>\n      <td>2015-01-12</td>\n      <td>2015-01-12</td>\n      <td>2015-01-13</td>\n      <td>2.985808</td>\n      <td>0.0896</td>\n      <td>0.100056</td>\n      <td>2</td>\n      <td>15</td>\n      <td>1759</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0</td>\n      <td>4041</td>\n      <td>2015-01-12</td>\n      <td>2015-01-12</td>\n      <td>2015-01-13</td>\n      <td>0.418013</td>\n      <td>0.0805</td>\n      <td>0.168161</td>\n      <td>2</td>\n      <td>15</td>\n      <td>1759</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/home/sergey/mnt/4.5Tb/Downloads/otus_final_input/data_encoded.csv\",\n",
    "                   low_memory=False,\n",
    "                   ).astype(config.dtypes)\n",
    "data = preprocess.preprocess(data)\n",
    "print(\"\", data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_val = data.groupby(data.Client_Id).tail(1)\n",
    "y_val = X_val.pop('target')\n",
    "X_train = data.drop(labels=X_val.index)\n",
    "y_train = X_train.pop('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "активность клиентов, простые статистики\n"
     ]
    },
    {
     "data": {
      "text/plain": "          DealDurationDays                   DealDurationMonths            \\\n                     count       mean median              count      mean   \nClient_Id                                                                   \n0                    16510  13.290612    7.0              16510  0.245548   \n7596                  3353   1.526991    1.0               3353  0.000000   \n17708                 2158   1.994903    1.0               2158  0.002780   \n8269                  1797   5.678353    6.0               1797  0.000000   \n11790                 1439  29.776928   26.0               1439  0.503127   \n...                    ...        ...    ...                ...       ...   \n1476                     1  28.000000   28.0                  1  0.000000   \n10884                    1   7.000000    7.0                  1  0.000000   \n1462                     1   3.000000    3.0                  1  0.000000   \n5381                     1  13.000000   13.0                  1  0.000000   \n6840                     1  33.000000   33.0                  1  1.000000   \n\n                 Client_Id               Deal_characteristics_1  ...  \\\n          median     count   mean median                  count  ...   \nClient_Id                                                        ...   \n0            0.0     16510      0      0                  16510  ...   \n7596         0.0      3353   7596   7596                   3353  ...   \n17708        0.0      2158  17708  17708                   2158  ...   \n8269         0.0      1797   8269   8269                   1797  ...   \n11790        0.0      1439  11790  11790                   1439  ...   \n...          ...       ...    ...    ...                    ...  ...   \n1476         0.0         1   1476   1476                      1  ...   \n10884        0.0         1  10884  10884                      1  ...   \n1462         0.0         1   1462   1462                      1  ...   \n5381         0.0         1   5381   5381                      1  ...   \n6840         1.0         1   6840   6840                      1  ...   \n\n          Deal_characteristics_3 Deal_characteristics_4                   \\\n                          median                  count      mean median   \nClient_Id                                                                  \n0                       0.074074                  16510  1.677832      2   \n7596                    0.067925                   3353  2.000000      2   \n17708                   0.076577                   2158  1.000000      1   \n8269                    0.080000                   1797  0.000000      0   \n11790                   0.079261                   1439  0.000000      0   \n...                          ...                    ...       ...    ...   \n1476                    0.127649                      1  0.000000      0   \n10884                   0.109683                      1  2.000000      2   \n1462                    0.120395                      1  2.000000      2   \n5381                    0.078762                      1  2.000000      2   \n6840                    0.086843                      1  2.000000      2   \n\n          Client_characteristics_1                   Client_characteristics_2  \\\n                             count       mean median                    count   \nClient_Id                                                                       \n0                            16510  10.497638   13.0                    16510   \n7596                          3353   7.232627    7.0                     3353   \n17708                         2158  15.000000   15.0                     2158   \n8269                          1797  10.648303   15.0                     1797   \n11790                         1439  10.970813   15.0                     1439   \n...                            ...        ...    ...                      ...   \n1476                             1  15.000000   15.0                        1   \n10884                            1  15.000000   15.0                        1   \n1462                             1  15.000000   15.0                        1   \n5381                             1  15.000000   15.0                        1   \n6840                             1  15.000000   15.0                        1   \n\n                                \n                  mean  median  \nClient_Id                       \n0          1308.578922  1737.0  \n7596        944.866090   954.0  \n17708      1759.000000  1759.0  \n8269       1004.415693  1759.0  \n11790      1467.997220  1759.0  \n...                ...     ...  \n1476       1759.000000  1759.0  \n10884      1759.000000  1759.0  \n1462       1759.000000  1759.0  \n5381       1759.000000  1759.0  \n6840       1759.000000  1759.0  \n\n[13050 rows x 27 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"3\" halign=\"left\">DealDurationDays</th>\n      <th colspan=\"3\" halign=\"left\">DealDurationMonths</th>\n      <th colspan=\"3\" halign=\"left\">Client_Id</th>\n      <th>Deal_characteristics_1</th>\n      <th>...</th>\n      <th>Deal_characteristics_3</th>\n      <th colspan=\"3\" halign=\"left\">Deal_characteristics_4</th>\n      <th colspan=\"3\" halign=\"left\">Client_characteristics_1</th>\n      <th colspan=\"3\" halign=\"left\">Client_characteristics_2</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>median</th>\n      <th>count</th>\n      <th>mean</th>\n      <th>median</th>\n      <th>count</th>\n      <th>mean</th>\n      <th>median</th>\n      <th>count</th>\n      <th>...</th>\n      <th>median</th>\n      <th>count</th>\n      <th>mean</th>\n      <th>median</th>\n      <th>count</th>\n      <th>mean</th>\n      <th>median</th>\n      <th>count</th>\n      <th>mean</th>\n      <th>median</th>\n    </tr>\n    <tr>\n      <th>Client_Id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>16510</td>\n      <td>13.290612</td>\n      <td>7.0</td>\n      <td>16510</td>\n      <td>0.245548</td>\n      <td>0.0</td>\n      <td>16510</td>\n      <td>0</td>\n      <td>0</td>\n      <td>16510</td>\n      <td>...</td>\n      <td>0.074074</td>\n      <td>16510</td>\n      <td>1.677832</td>\n      <td>2</td>\n      <td>16510</td>\n      <td>10.497638</td>\n      <td>13.0</td>\n      <td>16510</td>\n      <td>1308.578922</td>\n      <td>1737.0</td>\n    </tr>\n    <tr>\n      <th>7596</th>\n      <td>3353</td>\n      <td>1.526991</td>\n      <td>1.0</td>\n      <td>3353</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>3353</td>\n      <td>7596</td>\n      <td>7596</td>\n      <td>3353</td>\n      <td>...</td>\n      <td>0.067925</td>\n      <td>3353</td>\n      <td>2.000000</td>\n      <td>2</td>\n      <td>3353</td>\n      <td>7.232627</td>\n      <td>7.0</td>\n      <td>3353</td>\n      <td>944.866090</td>\n      <td>954.0</td>\n    </tr>\n    <tr>\n      <th>17708</th>\n      <td>2158</td>\n      <td>1.994903</td>\n      <td>1.0</td>\n      <td>2158</td>\n      <td>0.002780</td>\n      <td>0.0</td>\n      <td>2158</td>\n      <td>17708</td>\n      <td>17708</td>\n      <td>2158</td>\n      <td>...</td>\n      <td>0.076577</td>\n      <td>2158</td>\n      <td>1.000000</td>\n      <td>1</td>\n      <td>2158</td>\n      <td>15.000000</td>\n      <td>15.0</td>\n      <td>2158</td>\n      <td>1759.000000</td>\n      <td>1759.0</td>\n    </tr>\n    <tr>\n      <th>8269</th>\n      <td>1797</td>\n      <td>5.678353</td>\n      <td>6.0</td>\n      <td>1797</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1797</td>\n      <td>8269</td>\n      <td>8269</td>\n      <td>1797</td>\n      <td>...</td>\n      <td>0.080000</td>\n      <td>1797</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>1797</td>\n      <td>10.648303</td>\n      <td>15.0</td>\n      <td>1797</td>\n      <td>1004.415693</td>\n      <td>1759.0</td>\n    </tr>\n    <tr>\n      <th>11790</th>\n      <td>1439</td>\n      <td>29.776928</td>\n      <td>26.0</td>\n      <td>1439</td>\n      <td>0.503127</td>\n      <td>0.0</td>\n      <td>1439</td>\n      <td>11790</td>\n      <td>11790</td>\n      <td>1439</td>\n      <td>...</td>\n      <td>0.079261</td>\n      <td>1439</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>1439</td>\n      <td>10.970813</td>\n      <td>15.0</td>\n      <td>1439</td>\n      <td>1467.997220</td>\n      <td>1759.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1476</th>\n      <td>1</td>\n      <td>28.000000</td>\n      <td>28.0</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1476</td>\n      <td>1476</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.127649</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>1</td>\n      <td>15.000000</td>\n      <td>15.0</td>\n      <td>1</td>\n      <td>1759.000000</td>\n      <td>1759.0</td>\n    </tr>\n    <tr>\n      <th>10884</th>\n      <td>1</td>\n      <td>7.000000</td>\n      <td>7.0</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>10884</td>\n      <td>10884</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.109683</td>\n      <td>1</td>\n      <td>2.000000</td>\n      <td>2</td>\n      <td>1</td>\n      <td>15.000000</td>\n      <td>15.0</td>\n      <td>1</td>\n      <td>1759.000000</td>\n      <td>1759.0</td>\n    </tr>\n    <tr>\n      <th>1462</th>\n      <td>1</td>\n      <td>3.000000</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1462</td>\n      <td>1462</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.120395</td>\n      <td>1</td>\n      <td>2.000000</td>\n      <td>2</td>\n      <td>1</td>\n      <td>15.000000</td>\n      <td>15.0</td>\n      <td>1</td>\n      <td>1759.000000</td>\n      <td>1759.0</td>\n    </tr>\n    <tr>\n      <th>5381</th>\n      <td>1</td>\n      <td>13.000000</td>\n      <td>13.0</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>5381</td>\n      <td>5381</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.078762</td>\n      <td>1</td>\n      <td>2.000000</td>\n      <td>2</td>\n      <td>1</td>\n      <td>15.000000</td>\n      <td>15.0</td>\n      <td>1</td>\n      <td>1759.000000</td>\n      <td>1759.0</td>\n    </tr>\n    <tr>\n      <th>6840</th>\n      <td>1</td>\n      <td>33.000000</td>\n      <td>33.0</td>\n      <td>1</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>6840</td>\n      <td>6840</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.086843</td>\n      <td>1</td>\n      <td>2.000000</td>\n      <td>2</td>\n      <td>1</td>\n      <td>15.000000</td>\n      <td>15.0</td>\n      <td>1</td>\n      <td>1759.000000</td>\n      <td>1759.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>13050 rows × 27 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_id_activity = X_train.groupby(data.Client_Id).agg(['count', 'mean', 'median'])\n",
    "print('активность клиентов, простые статистики')\n",
    "client_id_activity.sort_values(by=('DealDurationDays', 'count'), ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "    X_train = X_train.merge(client_id_activity, how='left', left_on='Client_Id', right_index=True).dropna()\n",
    "    X_val = X_val.merge(client_id_activity, how='left', left_on='Client_Id', right_index=True)  # .dropna()\n",
    "# y_val = y_val[X_val.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape (274702, 13)\n",
      "X_train.shape (257180, 39)\n",
      "X_val.shape (17522, 39)\n",
      "data.shape[0] - X_val.shape[0] =  257180\n",
      "data.shape[0] -  X_train.shape[0] - X_val.shape[0] =  0\n",
      "13050 17522 -4472\n"
     ]
    }
   ],
   "source": [
    "print('data.shape', data.shape)\n",
    "print('X_train.shape', X_train.shape)\n",
    "print('X_val.shape', X_val.shape)\n",
    "print('data.shape[0] - X_val.shape[0] = ', data.shape[0] - X_val.shape[0])\n",
    "print('data.shape[0] -  X_train.shape[0] - X_val.shape[0] = ', data.shape[0] - X_train.shape[0] - X_val.shape[0])\n",
    "print(X_train.Client_Id.nunique(), X_val.Client_Id.nunique(), X_train.Client_Id.nunique() - X_val.Client_Id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_pool = Pool(data=X_train, label=y_train,\n",
    "                  cat_features=config.categorical_dtypes_ft.keys())\n",
    "val_pool = Pool(data=X_val, label=y_val,\n",
    "                cat_features=config.categorical_dtypes_ft.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## родная Logloss, catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.7196265\ttest: 0.6101332\tbest: 0.6101332 (0)\ttotal: 238ms\tremaining: 11.7s\n",
      "10:\tlearn: 0.7251849\ttest: 0.6145384\tbest: 0.6145384 (8)\ttotal: 2.08s\tremaining: 7.37s\n",
      "20:\tlearn: 0.7257784\ttest: 0.6147456\tbest: 0.6147749 (19)\ttotal: 4.15s\tremaining: 5.73s\n",
      "30:\tlearn: 0.7257723\ttest: 0.6147456\tbest: 0.6147749 (19)\ttotal: 6.06s\tremaining: 3.71s\n",
      "40:\tlearn: 0.7260305\ttest: 0.6151570\tbest: 0.6151570 (39)\ttotal: 8.02s\tremaining: 1.76s\n",
      "49:\tlearn: 0.7260443\ttest: 0.6151570\tbest: 0.6155390 (42)\ttotal: 9.63s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.6155390433\n",
      "bestIteration = 42\n",
      "\n",
      "Shrink model to first 43 iterations.\n",
      "CPU times: user 30.5 s, sys: 2.01 s, total: 32.5 s\n",
      "Wall time: 10.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": "<catboost.core.CatBoostClassifier at 0x7fe6f7af1910>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "iterations = 50\n",
    "params = config.params\n",
    "params.update({\n",
    "    'loss_function': 'Logloss',\n",
    "    'iterations': iterations,\n",
    "    'verbose': iterations // 5,\n",
    "})\n",
    "clf_ref_logloss = CatBoostClassifier(**params)\n",
    "clf_ref_logloss.fit(X=train_pool,\n",
    "        eval_set=val_pool,\n",
    "        use_best_model=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## внешняя реализация Logloss, numpy, catboost\n",
    "\n",
    "    Функция потерь logloss реализована через numpy, \n",
    "    работает экспоненцильано медленнее, чем родная от catboost\n",
    "    на 20 итерациях раз в 5 медленнее, на 200 - в 400 раз медленнее\n",
    "    но намного быстрее, чем если делать с циклом внутри \n",
    "    также сходится медленнее, чем родная. Сходимость одинаковая с реализацией через цикл \n",
    "    о сходимости есть топик на stackoverflow здесь \n",
    "\n",
    "        [](https://stackoverflow.com/questions/63104119/catboost-custom-loss-function)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.7196265\ttest: 0.6101332\tbest: 0.6101332 (0)\ttotal: 1.84s\tremaining: 1m 30s\n",
      "10:\tlearn: 0.7252499\ttest: 0.6145677\tbest: 0.6145677 (9)\ttotal: 21.6s\tremaining: 1m 16s\n",
      "20:\tlearn: 0.7253582\ttest: 0.6145872\tbest: 0.6145872 (16)\ttotal: 40.6s\tremaining: 56s\n",
      "30:\tlearn: 0.7258230\ttest: 0.6147771\tbest: 0.6147771 (25)\ttotal: 1m\tremaining: 36.8s\n",
      "40:\tlearn: 0.7259405\ttest: 0.6149471\tbest: 0.6149471 (39)\ttotal: 1m 19s\tremaining: 17.5s\n",
      "49:\tlearn: 0.7294851\ttest: 0.6185626\tbest: 0.6185633 (48)\ttotal: 1m 35s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.6185632879\n",
      "bestIteration = 48\n",
      "\n",
      "Shrink model to first 49 iterations.\n",
      "CPU times: user 1min 59s, sys: 10.7 s, total: 2min 9s\n",
      "Wall time: 1min 36s\n"
     ]
    },
    {
     "data": {
      "text/plain": "<catboost.core.CatBoostClassifier at 0x7fe6f7af1730>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "params = config.params\n",
    "params.update({\n",
    "    'loss_function': LoglossObjective_np(),\n",
    "    'iterations': iterations,\n",
    "    'verbose': iterations // 5,\n",
    "})\n",
    "clf_custom_logloss_np = CatBoostClassifier(**params)\n",
    "\n",
    "clf_custom_logloss_np.fit(X=train_pool,\n",
    "        eval_set=val_pool,\n",
    "        use_best_model=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## внешняя реализация Logloss, простой Python цикл,  catboost\n",
    "\n",
    "    Здесь функция потерь logloss реализована через цикл, очень медленно выполняется,\n",
    "    примерно в 8 раз медленнее, чем если реализовать через numpy \n",
    "    и в 30 раз медленнее, чем референсная, родная catboost \n",
    "    также сходится медленнее, чем родная. Сходимость одинаковая с реализацией через numpy \n",
    "\n",
    "    Результаты обоих внешних реализаций LogLoss эквивалентны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.7196265\ttest: 0.6101332\tbest: 0.6101332 (0)\ttotal: 6.45s\tremaining: 6.45s\n",
      "1:\tlearn: 0.7196265\ttest: 0.6101332\tbest: 0.6101332 (0)\ttotal: 13.2s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.6101332138\n",
      "bestIteration = 0\n",
      "\n",
      "Shrink model to first 1 iterations.\n",
      "CPU times: user 15.5 s, sys: 1.77 s, total: 17.3 s\n",
      "Wall time: 13.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": "<catboost.core.CatBoostClassifier at 0x7fe70498a940>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "params = config.params\n",
    "params.update({\n",
    "    'loss_function': LoglossObjective_loop(),\n",
    "    'iterations': 2,\n",
    "    'verbose': 4,\n",
    "})\n",
    "clf_logloss_custom_loop = CatBoostClassifier(**params)\n",
    "\n",
    "clf_logloss_custom_loop.fit(X=train_pool,\n",
    "        eval_set=val_pool,\n",
    "        use_best_model=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## внешняя реализация FocalLoss,\n",
    "Python, Numpy, первая и вторая производные получены в sympy,  catboost\n",
    "\n",
    "    Формулы функции потерь обозначены L\n",
    "    первая и вторая производные der1 и der2\n",
    "    \n",
    "    FocalLoss это частный случай AsymmetricLoss,\n",
    "    когда в формуле ниже gamma_minus == gamma_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Focal_der1, Focal_der2 = FocalLossFormulas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "## внешняя реализация AsymmetricLoss, ASL\n",
    "Python, Numpy, первая и вторая производные получены в sympy,  catboost\n",
    "\n",
    "    Формулы функции потерь обозначены L\n",
    "    первая и вторая производные der1 и der2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Eq(p, exp(x)/(exp(x) + 1))",
      "text/latex": "$\\displaystyle p = \\frac{e^{x}}{e^{x} + 1}$"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Eq(L_plus, (1 - exp(x)/(exp(x) + 1))**g_plus*log(exp(x)/(exp(x) + 1)))",
      "text/latex": "$\\displaystyle L_{plus} = \\left(1 - \\frac{e^{x}}{e^{x} + 1}\\right)^{g_{plus}} \\log{\\left(\\frac{e^{x}}{e^{x} + 1} \\right)}$"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Eq(L_minus, (exp(x)/(exp(x) + 1))**g_minus*log(1 - exp(x)/(exp(x) + 1)))",
      "text/latex": "$\\displaystyle L_{minus} = \\left(\\frac{e^{x}}{e^{x} + 1}\\right)^{g_{minus}} \\log{\\left(1 - \\frac{e^{x}}{e^{x} + 1} \\right)}$"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Eq(L, -y*(1 - exp(x)/(exp(x) + 1))**g_plus*log(exp(x)/(exp(x) + 1)) - (exp(x)/(exp(x) + 1))**g_minus*(1 - y)*log(1 - exp(x)/(exp(x) + 1)))",
      "text/latex": "$\\displaystyle L = - y \\left(1 - \\frac{e^{x}}{e^{x} + 1}\\right)^{g_{plus}} \\log{\\left(\\frac{e^{x}}{e^{x} + 1} \\right)} - \\left(\\frac{e^{x}}{e^{x} + 1}\\right)^{g_{minus}} \\left(1 - y\\right) \\log{\\left(1 - \\frac{e^{x}}{e^{x} + 1} \\right)}$"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Eq(L__der1, -g_minus*(exp(x)/(exp(x) + 1))**g_minus*(1 - y)*(exp(x)/(exp(x) + 1) - exp(2*x)/(exp(x) + 1)**2)*(exp(x) + 1)*exp(-x)*log(1 - exp(x)/(exp(x) + 1)) - g_plus*y*(1 - exp(x)/(exp(x) + 1))**g_plus*(-exp(x)/(exp(x) + 1) + exp(2*x)/(exp(x) + 1)**2)*log(exp(x)/(exp(x) + 1))/(1 - exp(x)/(exp(x) + 1)) - y*(1 - exp(x)/(exp(x) + 1))**g_plus*(exp(x)/(exp(x) + 1) - exp(2*x)/(exp(x) + 1)**2)*(exp(x) + 1)*exp(-x) - (exp(x)/(exp(x) + 1))**g_minus*(1 - y)*(-exp(x)/(exp(x) + 1) + exp(2*x)/(exp(x) + 1)**2)/(1 - exp(x)/(exp(x) + 1)))",
      "text/latex": "$\\displaystyle L^{der1} = - g_{minus} \\left(\\frac{e^{x}}{e^{x} + 1}\\right)^{g_{minus}} \\left(1 - y\\right) \\left(\\frac{e^{x}}{e^{x} + 1} - \\frac{e^{2 x}}{\\left(e^{x} + 1\\right)^{2}}\\right) \\left(e^{x} + 1\\right) e^{- x} \\log{\\left(1 - \\frac{e^{x}}{e^{x} + 1} \\right)} - \\frac{g_{plus} y \\left(1 - \\frac{e^{x}}{e^{x} + 1}\\right)^{g_{plus}} \\left(- \\frac{e^{x}}{e^{x} + 1} + \\frac{e^{2 x}}{\\left(e^{x} + 1\\right)^{2}}\\right) \\log{\\left(\\frac{e^{x}}{e^{x} + 1} \\right)}}{1 - \\frac{e^{x}}{e^{x} + 1}} - y \\left(1 - \\frac{e^{x}}{e^{x} + 1}\\right)^{g_{plus}} \\left(\\frac{e^{x}}{e^{x} + 1} - \\frac{e^{2 x}}{\\left(e^{x} + 1\\right)^{2}}\\right) \\left(e^{x} + 1\\right) e^{- x} - \\frac{\\left(\\frac{e^{x}}{e^{x} + 1}\\right)^{g_{minus}} \\left(1 - y\\right) \\left(- \\frac{e^{x}}{e^{x} + 1} + \\frac{e^{2 x}}{\\left(e^{x} + 1\\right)^{2}}\\right)}{1 - \\frac{e^{x}}{e^{x} + 1}}$"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Eq(L__der2, -g_minus**2*(exp(x)/(exp(x) + 1))**g_minus*(1 - y)*(exp(x)/(exp(x) + 1) - exp(2*x)/(exp(x) + 1)**2)**2*(exp(x) + 1)**2*exp(-2*x)*log(1 - exp(x)/(exp(x) + 1)) + g_minus*(exp(x)/(exp(x) + 1))**g_minus*(1 - y)*(exp(x)/(exp(x) + 1) - exp(2*x)/(exp(x) + 1)**2)*(exp(x) + 1)*exp(-x)*log(1 - exp(x)/(exp(x) + 1)) - g_minus*(exp(x)/(exp(x) + 1))**g_minus*(1 - y)*(exp(x)/(exp(x) + 1) - exp(2*x)/(exp(x) + 1)**2)*log(1 - exp(x)/(exp(x) + 1)) - g_minus*(exp(x)/(exp(x) + 1))**g_minus*(1 - y)*(exp(x) + 1)*(exp(x)/(exp(x) + 1) - 3*exp(2*x)/(exp(x) + 1)**2 + 2*exp(3*x)/(exp(x) + 1)**3)*exp(-x)*log(1 - exp(x)/(exp(x) + 1)) - 2*g_minus*(exp(x)/(exp(x) + 1))**g_minus*(1 - y)*(-exp(x)/(exp(x) + 1) + exp(2*x)/(exp(x) + 1)**2)*(exp(x)/(exp(x) + 1) - exp(2*x)/(exp(x) + 1)**2)*(exp(x) + 1)*exp(-x)/(1 - exp(x)/(exp(x) + 1)) - g_plus**2*y*(1 - exp(x)/(exp(x) + 1))**g_plus*(-exp(x)/(exp(x) + 1) + exp(2*x)/(exp(x) + 1)**2)**2*log(exp(x)/(exp(x) + 1))/(1 - exp(x)/(exp(x) + 1))**2 - 2*g_plus*y*(1 - exp(x)/(exp(x) + 1))**g_plus*(-exp(x)/(exp(x) + 1) + exp(2*x)/(exp(x) + 1)**2)*(exp(x)/(exp(x) + 1) - exp(2*x)/(exp(x) + 1)**2)*(exp(x) + 1)*exp(-x)/(1 - exp(x)/(exp(x) + 1)) - g_plus*y*(1 - exp(x)/(exp(x) + 1))**g_plus*(-exp(x)/(exp(x) + 1) + 3*exp(2*x)/(exp(x) + 1)**2 - 2*exp(3*x)/(exp(x) + 1)**3)*log(exp(x)/(exp(x) + 1))/(1 - exp(x)/(exp(x) + 1)) - g_plus*y*(1 - exp(x)/(exp(x) + 1))**g_plus*(-exp(x)/(exp(x) + 1) + exp(2*x)/(exp(x) + 1)**2)*(exp(x)/(exp(x) + 1) - exp(2*x)/(exp(x) + 1)**2)*log(exp(x)/(exp(x) + 1))/(1 - exp(x)/(exp(x) + 1))**2 + y*(1 - exp(x)/(exp(x) + 1))**g_plus*(exp(x)/(exp(x) + 1) - exp(2*x)/(exp(x) + 1)**2)*(exp(x) + 1)*exp(-x) - y*(1 - exp(x)/(exp(x) + 1))**g_plus*(exp(x)/(exp(x) + 1) - exp(2*x)/(exp(x) + 1)**2) - y*(1 - exp(x)/(exp(x) + 1))**g_plus*(exp(x) + 1)*(exp(x)/(exp(x) + 1) - 3*exp(2*x)/(exp(x) + 1)**2 + 2*exp(3*x)/(exp(x) + 1)**3)*exp(-x) - (exp(x)/(exp(x) + 1))**g_minus*(1 - y)*(-exp(x)/(exp(x) + 1) + 3*exp(2*x)/(exp(x) + 1)**2 - 2*exp(3*x)/(exp(x) + 1)**3)/(1 - exp(x)/(exp(x) + 1)) - (exp(x)/(exp(x) + 1))**g_minus*(1 - y)*(-exp(x)/(exp(x) + 1) + exp(2*x)/(exp(x) + 1)**2)*(exp(x)/(exp(x) + 1) - exp(2*x)/(exp(x) + 1)**2)/(1 - exp(x)/(exp(x) + 1))**2)",
      "text/latex": "$\\displaystyle L^{der2} = - g_{minus}^{2} \\left(\\frac{e^{x}}{e^{x} + 1}\\right)^{g_{minus}} \\left(1 - y\\right) \\left(\\frac{e^{x}}{e^{x} + 1} - \\frac{e^{2 x}}{\\left(e^{x} + 1\\right)^{2}}\\right)^{2} \\left(e^{x} + 1\\right)^{2} e^{- 2 x} \\log{\\left(1 - \\frac{e^{x}}{e^{x} + 1} \\right)} + g_{minus} \\left(\\frac{e^{x}}{e^{x} + 1}\\right)^{g_{minus}} \\left(1 - y\\right) \\left(\\frac{e^{x}}{e^{x} + 1} - \\frac{e^{2 x}}{\\left(e^{x} + 1\\right)^{2}}\\right) \\left(e^{x} + 1\\right) e^{- x} \\log{\\left(1 - \\frac{e^{x}}{e^{x} + 1} \\right)} - g_{minus} \\left(\\frac{e^{x}}{e^{x} + 1}\\right)^{g_{minus}} \\left(1 - y\\right) \\left(\\frac{e^{x}}{e^{x} + 1} - \\frac{e^{2 x}}{\\left(e^{x} + 1\\right)^{2}}\\right) \\log{\\left(1 - \\frac{e^{x}}{e^{x} + 1} \\right)} - g_{minus} \\left(\\frac{e^{x}}{e^{x} + 1}\\right)^{g_{minus}} \\left(1 - y\\right) \\left(e^{x} + 1\\right) \\left(\\frac{e^{x}}{e^{x} + 1} - \\frac{3 e^{2 x}}{\\left(e^{x} + 1\\right)^{2}} + \\frac{2 e^{3 x}}{\\left(e^{x} + 1\\right)^{3}}\\right) e^{- x} \\log{\\left(1 - \\frac{e^{x}}{e^{x} + 1} \\right)} - \\frac{2 g_{minus} \\left(\\frac{e^{x}}{e^{x} + 1}\\right)^{g_{minus}} \\left(1 - y\\right) \\left(- \\frac{e^{x}}{e^{x} + 1} + \\frac{e^{2 x}}{\\left(e^{x} + 1\\right)^{2}}\\right) \\left(\\frac{e^{x}}{e^{x} + 1} - \\frac{e^{2 x}}{\\left(e^{x} + 1\\right)^{2}}\\right) \\left(e^{x} + 1\\right) e^{- x}}{1 - \\frac{e^{x}}{e^{x} + 1}} - \\frac{g_{plus}^{2} y \\left(1 - \\frac{e^{x}}{e^{x} + 1}\\right)^{g_{plus}} \\left(- \\frac{e^{x}}{e^{x} + 1} + \\frac{e^{2 x}}{\\left(e^{x} + 1\\right)^{2}}\\right)^{2} \\log{\\left(\\frac{e^{x}}{e^{x} + 1} \\right)}}{\\left(1 - \\frac{e^{x}}{e^{x} + 1}\\right)^{2}} - \\frac{2 g_{plus} y \\left(1 - \\frac{e^{x}}{e^{x} + 1}\\right)^{g_{plus}} \\left(- \\frac{e^{x}}{e^{x} + 1} + \\frac{e^{2 x}}{\\left(e^{x} + 1\\right)^{2}}\\right) \\left(\\frac{e^{x}}{e^{x} + 1} - \\frac{e^{2 x}}{\\left(e^{x} + 1\\right)^{2}}\\right) \\left(e^{x} + 1\\right) e^{- x}}{1 - \\frac{e^{x}}{e^{x} + 1}} - \\frac{g_{plus} y \\left(1 - \\frac{e^{x}}{e^{x} + 1}\\right)^{g_{plus}} \\left(- \\frac{e^{x}}{e^{x} + 1} + \\frac{3 e^{2 x}}{\\left(e^{x} + 1\\right)^{2}} - \\frac{2 e^{3 x}}{\\left(e^{x} + 1\\right)^{3}}\\right) \\log{\\left(\\frac{e^{x}}{e^{x} + 1} \\right)}}{1 - \\frac{e^{x}}{e^{x} + 1}} - \\frac{g_{plus} y \\left(1 - \\frac{e^{x}}{e^{x} + 1}\\right)^{g_{plus}} \\left(- \\frac{e^{x}}{e^{x} + 1} + \\frac{e^{2 x}}{\\left(e^{x} + 1\\right)^{2}}\\right) \\left(\\frac{e^{x}}{e^{x} + 1} - \\frac{e^{2 x}}{\\left(e^{x} + 1\\right)^{2}}\\right) \\log{\\left(\\frac{e^{x}}{e^{x} + 1} \\right)}}{\\left(1 - \\frac{e^{x}}{e^{x} + 1}\\right)^{2}} + y \\left(1 - \\frac{e^{x}}{e^{x} + 1}\\right)^{g_{plus}} \\left(\\frac{e^{x}}{e^{x} + 1} - \\frac{e^{2 x}}{\\left(e^{x} + 1\\right)^{2}}\\right) \\left(e^{x} + 1\\right) e^{- x} - y \\left(1 - \\frac{e^{x}}{e^{x} + 1}\\right)^{g_{plus}} \\left(\\frac{e^{x}}{e^{x} + 1} - \\frac{e^{2 x}}{\\left(e^{x} + 1\\right)^{2}}\\right) - y \\left(1 - \\frac{e^{x}}{e^{x} + 1}\\right)^{g_{plus}} \\left(e^{x} + 1\\right) \\left(\\frac{e^{x}}{e^{x} + 1} - \\frac{3 e^{2 x}}{\\left(e^{x} + 1\\right)^{2}} + \\frac{2 e^{3 x}}{\\left(e^{x} + 1\\right)^{3}}\\right) e^{- x} - \\frac{\\left(\\frac{e^{x}}{e^{x} + 1}\\right)^{g_{minus}} \\left(1 - y\\right) \\left(- \\frac{e^{x}}{e^{x} + 1} + \\frac{3 e^{2 x}}{\\left(e^{x} + 1\\right)^{2}} - \\frac{2 e^{3 x}}{\\left(e^{x} + 1\\right)^{3}}\\right)}{1 - \\frac{e^{x}}{e^{x} + 1}} - \\frac{\\left(\\frac{e^{x}}{e^{x} + 1}\\right)^{g_{minus}} \\left(1 - y\\right) \\left(- \\frac{e^{x}}{e^{x} + 1} + \\frac{e^{2 x}}{\\left(e^{x} + 1\\right)^{2}}\\right) \\left(\\frac{e^{x}}{e^{x} + 1} - \\frac{e^{2 x}}{\\left(e^{x} + 1\\right)^{2}}\\right)}{\\left(1 - \\frac{e^{x}}{e^{x} + 1}\\right)^{2}}$"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ASL_der1, ASL_der2 = AsymmetricLossFormulas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Упрощенная производная асимметричной функции потерь ASL\n",
    "      упрощение удаляет все экспоненты, оставляет только логарифмы\n",
    "      вторая производная намного длиннее, здесь я её не печатаю"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'Входящая функция производной'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Eq(ASL_der1, -g_minus*(exp(x)/(exp(x) + 1))**g_minus*(1 - y)*(exp(x)/(exp(x) + 1) - exp(2*x)/(exp(x) + 1)**2)*(exp(x) + 1)*exp(-x)*log(1 - exp(x)/(exp(x) + 1)) - g_plus*y*(1 - exp(x)/(exp(x) + 1))**g_plus*(-exp(x)/(exp(x) + 1) + exp(2*x)/(exp(x) + 1)**2)*log(exp(x)/(exp(x) + 1))/(1 - exp(x)/(exp(x) + 1)) - y*(1 - exp(x)/(exp(x) + 1))**g_plus*(exp(x)/(exp(x) + 1) - exp(2*x)/(exp(x) + 1)**2)*(exp(x) + 1)*exp(-x) - (exp(x)/(exp(x) + 1))**g_minus*(1 - y)*(-exp(x)/(exp(x) + 1) + exp(2*x)/(exp(x) + 1)**2)/(1 - exp(x)/(exp(x) + 1)))",
      "text/latex": "$\\displaystyle ASL_{der1} = - g_{minus} \\left(\\frac{e^{x}}{e^{x} + 1}\\right)^{g_{minus}} \\left(1 - y\\right) \\left(\\frac{e^{x}}{e^{x} + 1} - \\frac{e^{2 x}}{\\left(e^{x} + 1\\right)^{2}}\\right) \\left(e^{x} + 1\\right) e^{- x} \\log{\\left(1 - \\frac{e^{x}}{e^{x} + 1} \\right)} - \\frac{g_{plus} y \\left(1 - \\frac{e^{x}}{e^{x} + 1}\\right)^{g_{plus}} \\left(- \\frac{e^{x}}{e^{x} + 1} + \\frac{e^{2 x}}{\\left(e^{x} + 1\\right)^{2}}\\right) \\log{\\left(\\frac{e^{x}}{e^{x} + 1} \\right)}}{1 - \\frac{e^{x}}{e^{x} + 1}} - y \\left(1 - \\frac{e^{x}}{e^{x} + 1}\\right)^{g_{plus}} \\left(\\frac{e^{x}}{e^{x} + 1} - \\frac{e^{2 x}}{\\left(e^{x} + 1\\right)^{2}}\\right) \\left(e^{x} + 1\\right) e^{- x} - \\frac{\\left(\\frac{e^{x}}{e^{x} + 1}\\right)^{g_{minus}} \\left(1 - y\\right) \\left(- \\frac{e^{x}}{e^{x} + 1} + \\frac{e^{2 x}}{\\left(e^{x} + 1\\right)^{2}}\\right)}{1 - \\frac{e^{x}}{e^{x} + 1}}$"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'*********** der.subs(sp.exp(x) / (1 + sp.exp(x)), p) *************'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Eq(ASL_der1, -g_minus*p**g_minus*(1 - y)*(-p**2 + p)*(exp(x) + 1)*exp(-x)*log(1 - p) - g_plus*y*(1 - p)**g_plus*(p**2 - p)*log(p)/(1 - p) - p**g_minus*(1 - y)*(p**2 - p)/(1 - p) - y*(1 - p)**g_plus*(-p**2 + p)*(exp(x) + 1)*exp(-x))",
      "text/latex": "$\\displaystyle ASL_{der1} = - g_{minus} p^{g_{minus}} \\left(1 - y\\right) \\left(- p^{2} + p\\right) \\left(e^{x} + 1\\right) e^{- x} \\log{\\left(1 - p \\right)} - \\frac{g_{plus} y \\left(1 - p\\right)^{g_{plus}} \\left(p^{2} - p\\right) \\log{\\left(p \\right)}}{1 - p} - \\frac{p^{g_{minus}} \\left(1 - y\\right) \\left(p^{2} - p\\right)}{1 - p} - y \\left(1 - p\\right)^{g_{plus}} \\left(- p^{2} + p\\right) \\left(e^{x} + 1\\right) e^{- x}$"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'*********** der.subs(sp.exp(x) / (1 + sp.exp(x)), p) *************'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Eq(ASL_der1, -g_minus*p**g_minus*(1 - y)*(-p**2 + p)*(exp(x) + 1)*exp(-x)*log(1 - p) - g_plus*y*(1 - p)**g_plus*(p**2 - p)*log(p)/(1 - p) - p**g_minus*(1 - y)*(p**2 - p)/(1 - p) - y*(1 - p)**g_plus*(-p**2 + p)*(exp(x) + 1)*exp(-x))",
      "text/latex": "$\\displaystyle ASL_{der1} = - g_{minus} p^{g_{minus}} \\left(1 - y\\right) \\left(- p^{2} + p\\right) \\left(e^{x} + 1\\right) e^{- x} \\log{\\left(1 - p \\right)} - \\frac{g_{plus} y \\left(1 - p\\right)^{g_{plus}} \\left(p^{2} - p\\right) \\log{\\left(p \\right)}}{1 - p} - \\frac{p^{g_{minus}} \\left(1 - y\\right) \\left(p^{2} - p\\right)}{1 - p} - y \\left(1 - p\\right)^{g_{plus}} \\left(- p^{2} + p\\right) \\left(e^{x} + 1\\right) e^{- x}$"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'**********    der.subs((1 + sp.exp(x))**2 * sp.exp(x)**(-2), p**(-2))  *****************'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Eq(ASL_der1, -g_minus*p**g_minus*(1 - y)*(-p**2 + p)*(exp(x) + 1)*exp(-x)*log(1 - p) - g_plus*y*(1 - p)**g_plus*(p**2 - p)*log(p)/(1 - p) - p**g_minus*(1 - y)*(p**2 - p)/(1 - p) - y*(1 - p)**g_plus*(-p**2 + p)*(exp(x) + 1)*exp(-x))",
      "text/latex": "$\\displaystyle ASL_{der1} = - g_{minus} p^{g_{minus}} \\left(1 - y\\right) \\left(- p^{2} + p\\right) \\left(e^{x} + 1\\right) e^{- x} \\log{\\left(1 - p \\right)} - \\frac{g_{plus} y \\left(1 - p\\right)^{g_{plus}} \\left(p^{2} - p\\right) \\log{\\left(p \\right)}}{1 - p} - \\frac{p^{g_{minus}} \\left(1 - y\\right) \\left(p^{2} - p\\right)}{1 - p} - y \\left(1 - p\\right)^{g_{plus}} \\left(- p^{2} + p\\right) \\left(e^{x} + 1\\right) e^{- x}$"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'*********** sp.symplify(der) *************'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Eq(ASL_der1, p*((p - 1)*(-g_minus*p**g_minus*(y - 1)*log(1 - p) + y*(1 - p)**g_plus)*(exp(x) + 1) + (g_plus*y*(1 - p)**g_plus*log(p) - p**g_minus*(y - 1))*exp(x))*exp(-x))",
      "text/latex": "$\\displaystyle ASL_{der1} = p \\left(\\left(p - 1\\right) \\left(- g_{minus} p^{g_{minus}} \\left(y - 1\\right) \\log{\\left(1 - p \\right)} + y \\left(1 - p\\right)^{g_{plus}}\\right) \\left(e^{x} + 1\\right) + \\left(g_{plus} y \\left(1 - p\\right)^{g_{plus}} \\log{\\left(p \\right)} - p^{g_{minus}} \\left(y - 1\\right)\\right) e^{x}\\right) e^{- x}$"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'*********** sp.factor(der) *************'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Eq(ASL_der1, p*(-g_minus*p*p**g_minus*y*exp(x)*log(1 - p) - g_minus*p*p**g_minus*y*log(1 - p) + g_minus*p*p**g_minus*exp(x)*log(1 - p) + g_minus*p*p**g_minus*log(1 - p) + g_minus*p**g_minus*y*exp(x)*log(1 - p) + g_minus*p**g_minus*y*log(1 - p) - g_minus*p**g_minus*exp(x)*log(1 - p) - g_minus*p**g_minus*log(1 - p) + g_plus*y*(1 - p)**g_plus*exp(x)*log(p) + p*y*(1 - p)**g_plus*exp(x) + p*y*(1 - p)**g_plus - p**g_minus*y*exp(x) + p**g_minus*exp(x) - y*(1 - p)**g_plus*exp(x) - y*(1 - p)**g_plus)*exp(-x))",
      "text/latex": "$\\displaystyle ASL_{der1} = p \\left(- g_{minus} p p^{g_{minus}} y e^{x} \\log{\\left(1 - p \\right)} - g_{minus} p p^{g_{minus}} y \\log{\\left(1 - p \\right)} + g_{minus} p p^{g_{minus}} e^{x} \\log{\\left(1 - p \\right)} + g_{minus} p p^{g_{minus}} \\log{\\left(1 - p \\right)} + g_{minus} p^{g_{minus}} y e^{x} \\log{\\left(1 - p \\right)} + g_{minus} p^{g_{minus}} y \\log{\\left(1 - p \\right)} - g_{minus} p^{g_{minus}} e^{x} \\log{\\left(1 - p \\right)} - g_{minus} p^{g_{minus}} \\log{\\left(1 - p \\right)} + g_{plus} y \\left(1 - p\\right)^{g_{plus}} e^{x} \\log{\\left(p \\right)} + p y \\left(1 - p\\right)^{g_{plus}} e^{x} + p y \\left(1 - p\\right)^{g_{plus}} - p^{g_{minus}} y e^{x} + p^{g_{minus}} e^{x} - y \\left(1 - p\\right)^{g_{plus}} e^{x} - y \\left(1 - p\\right)^{g_{plus}}\\right) e^{- x}$"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'*********** sp.factor(der) *************'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Eq(ASL_der1, p*(-g_minus*p*p**g_minus*y*exp(x)*log(1 - p) - g_minus*p*p**g_minus*y*log(1 - p) + g_minus*p*p**g_minus*exp(x)*log(1 - p) + g_minus*p*p**g_minus*log(1 - p) + g_minus*p**g_minus*y*exp(x)*log(1 - p) + g_minus*p**g_minus*y*log(1 - p) - g_minus*p**g_minus*exp(x)*log(1 - p) - g_minus*p**g_minus*log(1 - p) + g_plus*y*(1 - p)**g_plus*exp(x)*log(p) + p*y*(1 - p)**g_plus*exp(x) + p*y*(1 - p)**g_plus - p**g_minus*y*exp(x) + p**g_minus*exp(x) - y*(1 - p)**g_plus*exp(x) - y*(1 - p)**g_plus)*exp(-x))",
      "text/latex": "$\\displaystyle ASL_{der1} = p \\left(- g_{minus} p p^{g_{minus}} y e^{x} \\log{\\left(1 - p \\right)} - g_{minus} p p^{g_{minus}} y \\log{\\left(1 - p \\right)} + g_{minus} p p^{g_{minus}} e^{x} \\log{\\left(1 - p \\right)} + g_{minus} p p^{g_{minus}} \\log{\\left(1 - p \\right)} + g_{minus} p^{g_{minus}} y e^{x} \\log{\\left(1 - p \\right)} + g_{minus} p^{g_{minus}} y \\log{\\left(1 - p \\right)} - g_{minus} p^{g_{minus}} e^{x} \\log{\\left(1 - p \\right)} - g_{minus} p^{g_{minus}} \\log{\\left(1 - p \\right)} + g_{plus} y \\left(1 - p\\right)^{g_{plus}} e^{x} \\log{\\left(p \\right)} + p y \\left(1 - p\\right)^{g_{plus}} e^{x} + p y \\left(1 - p\\right)^{g_{plus}} - p^{g_{minus}} y e^{x} + p^{g_{minus}} e^{x} - y \\left(1 - p\\right)^{g_{plus}} e^{x} - y \\left(1 - p\\right)^{g_{plus}}\\right) e^{- x}$"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'*********** sp.symplify(der) *************'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Eq(ASL_der1, p*(g_minus*p**g_minus*y*exp(x)*log(1 - p) + g_minus*p**g_minus*y*log(1 - p) - g_minus*p**g_minus*exp(x)*log(1 - p) - g_minus*p**g_minus*log(1 - p) - g_minus*p**(g_minus + 1)*y*exp(x)*log(1 - p) - g_minus*p**(g_minus + 1)*y*log(1 - p) + g_minus*p**(g_minus + 1)*exp(x)*log(1 - p) + g_minus*p**(g_minus + 1)*log(1 - p) + g_plus*y*(1 - p)**g_plus*exp(x)*log(p) + p*y*(1 - p)**g_plus*exp(x) + p*y*(1 - p)**g_plus - p**g_minus*y*exp(x) + p**g_minus*exp(x) - y*(1 - p)**g_plus*exp(x) - y*(1 - p)**g_plus)*exp(-x))",
      "text/latex": "$\\displaystyle ASL_{der1} = p \\left(g_{minus} p^{g_{minus}} y e^{x} \\log{\\left(1 - p \\right)} + g_{minus} p^{g_{minus}} y \\log{\\left(1 - p \\right)} - g_{minus} p^{g_{minus}} e^{x} \\log{\\left(1 - p \\right)} - g_{minus} p^{g_{minus}} \\log{\\left(1 - p \\right)} - g_{minus} p^{g_{minus} + 1} y e^{x} \\log{\\left(1 - p \\right)} - g_{minus} p^{g_{minus} + 1} y \\log{\\left(1 - p \\right)} + g_{minus} p^{g_{minus} + 1} e^{x} \\log{\\left(1 - p \\right)} + g_{minus} p^{g_{minus} + 1} \\log{\\left(1 - p \\right)} + g_{plus} y \\left(1 - p\\right)^{g_{plus}} e^{x} \\log{\\left(p \\right)} + p y \\left(1 - p\\right)^{g_{plus}} e^{x} + p y \\left(1 - p\\right)^{g_{plus}} - p^{g_{minus}} y e^{x} + p^{g_{minus}} e^{x} - y \\left(1 - p\\right)^{g_{plus}} e^{x} - y \\left(1 - p\\right)^{g_{plus}}\\right) e^{- x}$"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'**********    der.subs(sp.exp(x), p / (1-p))  *****************'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Eq(ASL_der1, (1 - p)*(g_minus*p*p**g_minus*y*log(1 - p)/(1 - p) - g_minus*p*p**g_minus*log(1 - p)/(1 - p) - g_minus*p*p**(g_minus + 1)*y*log(1 - p)/(1 - p) + g_minus*p*p**(g_minus + 1)*log(1 - p)/(1 - p) + g_minus*p**g_minus*y*log(1 - p) - g_minus*p**g_minus*log(1 - p) - g_minus*p**(g_minus + 1)*y*log(1 - p) + g_minus*p**(g_minus + 1)*log(1 - p) + g_plus*p*y*(1 - p)**g_plus*log(p)/(1 - p) + p**2*y*(1 - p)**g_plus/(1 - p) - p*p**g_minus*y/(1 - p) + p*p**g_minus/(1 - p) + p*y*(1 - p)**g_plus - p*y*(1 - p)**g_plus/(1 - p) - y*(1 - p)**g_plus))",
      "text/latex": "$\\displaystyle ASL_{der1} = \\left(1 - p\\right) \\left(\\frac{g_{minus} p p^{g_{minus}} y \\log{\\left(1 - p \\right)}}{1 - p} - \\frac{g_{minus} p p^{g_{minus}} \\log{\\left(1 - p \\right)}}{1 - p} - \\frac{g_{minus} p p^{g_{minus} + 1} y \\log{\\left(1 - p \\right)}}{1 - p} + \\frac{g_{minus} p p^{g_{minus} + 1} \\log{\\left(1 - p \\right)}}{1 - p} + g_{minus} p^{g_{minus}} y \\log{\\left(1 - p \\right)} - g_{minus} p^{g_{minus}} \\log{\\left(1 - p \\right)} - g_{minus} p^{g_{minus} + 1} y \\log{\\left(1 - p \\right)} + g_{minus} p^{g_{minus} + 1} \\log{\\left(1 - p \\right)} + \\frac{g_{plus} p y \\left(1 - p\\right)^{g_{plus}} \\log{\\left(p \\right)}}{1 - p} + \\frac{p^{2} y \\left(1 - p\\right)^{g_{plus}}}{1 - p} - \\frac{p p^{g_{minus}} y}{1 - p} + \\frac{p p^{g_{minus}}}{1 - p} + p y \\left(1 - p\\right)^{g_{plus}} - \\frac{p y \\left(1 - p\\right)^{g_{plus}}}{1 - p} - y \\left(1 - p\\right)^{g_{plus}}\\right)$"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'*********** sp.factor(der) *************'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Eq(ASL_der1, -g_minus*p*p**g_minus*y*log(1 - p) + g_minus*p*p**g_minus*log(1 - p) + g_minus*p**g_minus*y*log(1 - p) - g_minus*p**g_minus*log(1 - p) + g_plus*p*y*(1 - p)**g_plus*log(p) - p*p**g_minus*y + p*p**g_minus + p*y*(1 - p)**g_plus - y*(1 - p)**g_plus)",
      "text/latex": "$\\displaystyle ASL_{der1} = - g_{minus} p p^{g_{minus}} y \\log{\\left(1 - p \\right)} + g_{minus} p p^{g_{minus}} \\log{\\left(1 - p \\right)} + g_{minus} p^{g_{minus}} y \\log{\\left(1 - p \\right)} - g_{minus} p^{g_{minus}} \\log{\\left(1 - p \\right)} + g_{plus} p y \\left(1 - p\\right)^{g_{plus}} \\log{\\left(p \\right)} - p p^{g_{minus}} y + p p^{g_{minus}} + p y \\left(1 - p\\right)^{g_{plus}} - y \\left(1 - p\\right)^{g_{plus}}$"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'*********** sp.symplify(der) *************'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Eq(ASL_der1, g_minus*p**g_minus*y*log(1 - p) - g_minus*p**g_minus*log(1 - p) - g_minus*p**(g_minus + 1)*y*log(1 - p) + g_minus*p**(g_minus + 1)*log(1 - p) + g_plus*p*y*(1 - p)**g_plus*log(p) + p*y*(1 - p)**g_plus - p**(g_minus + 1)*y + p**(g_minus + 1) - y*(1 - p)**g_plus)",
      "text/latex": "$\\displaystyle ASL_{der1} = g_{minus} p^{g_{minus}} y \\log{\\left(1 - p \\right)} - g_{minus} p^{g_{minus}} \\log{\\left(1 - p \\right)} - g_{minus} p^{g_{minus} + 1} y \\log{\\left(1 - p \\right)} + g_{minus} p^{g_{minus} + 1} \\log{\\left(1 - p \\right)} + g_{plus} p y \\left(1 - p\\right)^{g_{plus}} \\log{\\left(p \\right)} + p y \\left(1 - p\\right)^{g_{plus}} - p^{g_{minus} + 1} y + p^{g_{minus} + 1} - y \\left(1 - p\\right)^{g_{plus}}$"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ASL_der1_simplified = get_simplified_derivative(ASL_der1, verbose=True, der_name='ASL_der1')\n",
    "ASL_der2_simplified = get_simplified_derivative(ASL_der2, verbose=False, der_name='ASL_der2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# вычисление модели с асимметричной функцией потерь\n",
    "### Здесь функция потерь AsymmetricLoss ASL реализована через numpy, Python\n",
    "      формула приводится выше\n",
    "      gamma - это гиперпараметры модели, их можно подбирать HyperBand'ом, к примеру\n",
    "      Здесь я оптимизирую  AUC, метрику F_beta не успел доделать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.7196265\ttest: 0.6101332\tbest: 0.6101332 (0)\ttotal: 19.7s\tremaining: 16m 7s\n",
      "10:\tlearn: 0.7265703\ttest: 0.6163402\tbest: 0.6163402 (10)\ttotal: 3m 56s\tremaining: 13m 58s\n",
      "20:\tlearn: 0.7267891\ttest: 0.6163860\tbest: 0.6163860 (20)\ttotal: 7m 4s\tremaining: 9m 45s\n",
      "30:\tlearn: 0.7272849\ttest: 0.6172047\tbest: 0.6172047 (29)\ttotal: 10m 14s\tremaining: 6m 16s\n",
      "40:\tlearn: 0.7271928\ttest: 0.6172308\tbest: 0.6172308 (33)\ttotal: 14m 12s\tremaining: 3m 7s\n",
      "49:\tlearn: 0.7291334\ttest: 0.6178568\tbest: 0.6180609 (44)\ttotal: 17m 58s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.6180609122\n",
      "bestIteration = 44\n",
      "\n",
      "Shrink model to first 45 iterations.\n",
      "CPU times: user 19min 29s, sys: 1min 50s, total: 21min 19s\n",
      "Wall time: 17min 59s\n"
     ]
    },
    {
     "data": {
      "text/plain": "<catboost.core.CatBoostClassifier at 0x7fe704650460>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "params = config.params\n",
    "params.update({\n",
    "    'loss_function': AsymmetricLossObjective(der1=ASL_der1_simplified,\n",
    "                                             der2=ASL_der2_simplified,\n",
    "                                             gamma_minus=0.2,\n",
    "                                             gamma_plus=0.6),\n",
    "    'iterations': iterations,\n",
    "    'verbose': iterations // 5,\n",
    "})\n",
    "clf_custom_asl = CatBoostClassifier(**params)\n",
    "clf_custom_asl.fit(X=train_pool,\n",
    "        eval_set=val_pool,\n",
    "        use_best_model=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Здесь функция потерь FocalLoss реализована через numpy, Python как частный случай ASL\n",
    "\n",
    "      FocalLoss это частный случай AsymmetricLoss ASL,\n",
    "      когда в формуле аргумент gamma_minus == gamma_plus\n",
    "\n",
    "            формула приводится выше\n",
    "      gamma - это гиперпараметры модели, их можно подбирать HyperBand'ом, к примеру\n",
    "      Здесь я оптимизирую AUC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.7196265\ttest: 0.6101332\tbest: 0.6101332 (0)\ttotal: 23.3s\tremaining: 19m 2s\n",
      "10:\tlearn: 0.7252499\ttest: 0.6145677\tbest: 0.6145677 (9)\ttotal: 4m 20s\tremaining: 15m 22s\n",
      "20:\tlearn: 0.7253582\ttest: 0.6145872\tbest: 0.6145872 (16)\ttotal: 8m 3s\tremaining: 11m 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = config.params\n",
    "params.update({\n",
    "    'loss_function': AsymmetricLossObjective(der1=ASL_der1_simplified,\n",
    "                                             der2=ASL_der2_simplified,\n",
    "                                             gamma_minus=0.5,\n",
    "                                             gamma_plus=0.5),\n",
    "    'iterations': iterations,\n",
    "    'verbose': iterations // 5,\n",
    "})\n",
    "clf_custom_focalloss = CatBoostClassifier(**params)\n",
    "clf_custom_focalloss.fit(X=train_pool,\n",
    "        eval_set=val_pool,\n",
    "        use_best_model=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = {\n",
    "    'reference_logloss': clf_ref_logloss.get_evals_result()['validation'],\n",
    "    'numpy Python': clf_custom_logloss_np.get_evals_result()['validation'],\n",
    "    'ASL': clf_custom_asl.get_evals_result()['validation'],\n",
    "    'FocalLoss': clf_custom_focalloss.get_evals_result()['validation'],\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_result_metric(metric):\n",
    "    fig = plt.figure()\n",
    "    plt.title(label=metric)\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    evals_df = pd.DataFrame()\n",
    "\n",
    "    for label, evals in results.items():\n",
    "        evals_df[label] = evals[metric]\n",
    "        ax.plot(evals[metric], label=label)\n",
    "    print(evals_df.tail())\n",
    "\n",
    "    plt.xlabel('iterations')\n",
    "    plt.ylabel(f'{metric} score')\n",
    "    plt.legend()\n",
    "    plt.show();"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_result_metric(\"AUC\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_result_metric('F1')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Ссылки\n",
    "    [Статья с описанием AsymmetricLoss на arxiv.org](https://arxiv.org/pdf/2009.14119.pdf)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "#                               СПАСИБО"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}